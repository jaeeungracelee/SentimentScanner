{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f4dc04",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fd17789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from statistics import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830f62b",
   "metadata": {},
   "source": [
    "# Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b522d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: Windows-1252\n",
      "DataFrame read with detected encoding:\n",
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                         selected_text sentiment Time of Tweet Age of User  \\\n",
      "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
      "1                             Sooo SAD  negative          noon       21-30   \n",
      "2                          bullying me  negative         night       31-45   \n",
      "3                       leave me alone  negative       morning       46-60   \n",
      "4                        Sons of ****,  negative          noon       60-70   \n",
      "\n",
      "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
      "0  Afghanistan          38928346         652860.0               60  \n",
      "1      Albania           2877797          27400.0              105  \n",
      "2      Algeria          43851044        2381740.0               18  \n",
      "3      Andorra             77265            470.0              164  \n",
      "4       Angola          32866272        1246700.0               26  \n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "file_path = '../data/train.csv'\n",
    "# Detect file encoding\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    detected_encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {detected_encoding}\")\n",
    "\n",
    "# Read the CSV file using the detected encoding\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding=detected_encoding)\n",
    "    print(\"DataFrame read with detected encoding:\")\n",
    "    print(df.head())\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"UnicodeDecodeError with detected encoding: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47b5eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with Nan text\n",
    "df_train_text = df['text']\n",
    "mask = df_train_text.apply(lambda x: isinstance(x, float))\n",
    "rows_with_float_text = df[mask] \n",
    "indices = rows_with_float_text.index.tolist()\n",
    "df_train = df.drop(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f823a",
   "metadata": {},
   "source": [
    "# Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "020cc819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: Windows-1252\n",
      "DataFrame read with detected encoding:\n",
      "       textID                                               text sentiment  \\\n",
      "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
      "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
      "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
      "3  01082688c6                                        happy bday!  positive   \n",
      "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
      "\n",
      "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
      "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
      "1          noon       21-30      Albania         2877797.0          27400.0   \n",
      "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
      "3       morning       46-60      Andorra           77265.0            470.0   \n",
      "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
      "\n",
      "   Density (P/Km²)  \n",
      "0             60.0  \n",
      "1            105.0  \n",
      "2             18.0  \n",
      "3            164.0  \n",
      "4             26.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/test.csv'\n",
    "# Detect file encoding\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    detected_encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {detected_encoding}\")\n",
    "\n",
    "# Read the CSV file using the detected encoding\n",
    "try:\n",
    "    df_test = pd.read_csv(file_path, encoding=detected_encoding)\n",
    "    print(\"DataFrame read with detected encoding:\")\n",
    "    print(df_test.head())\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"UnicodeDecodeError with detected encoding: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d72268a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with Nan text\n",
    "df_test_text = df_test['text']\n",
    "mask = df_test_text.apply(lambda x: isinstance(x, float))\n",
    "rows_with_float_text = df_test[mask] \n",
    "indices = rows_with_float_text.index.tolist()\n",
    "df_test = df_test.drop(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703b5b6",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c5882b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_sentiment(data, sentiment):\n",
    "    return data[data['sentiment'] == sentiment]['text'].tolist()\n",
    "\n",
    "# Assuming df is your DataFrame containing 'text' and 'sentiment' columns\n",
    "positive_data = split_data_by_sentiment(df, 'positive')\n",
    "negative_data = split_data_by_sentiment(df, 'negative')\n",
    "neutral_data = split_data_by_sentiment(df, 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6806c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    \n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    tweet = re.sub(r'\\W+', ' ', tweet)\n",
    "    \n",
    "    # Convert the tweet to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove punctuation from the tweet using translation\n",
    "    tweet = tweet.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize the tweet into individual words\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    \n",
    "    # Initialize a Porter stemmer for word stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Get a set of English stopwords from NLTK\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Apply stemming to each token and filter out stopwords\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token not in stopwords_set]\n",
    "    \n",
    "    # Return the preprocessed tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4d7095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_counts(tweets):\n",
    "    # Initialize a defaultdict to store word counts, defaulting to 0 for unseen words\n",
    "    word_count = defaultdict(int)\n",
    "    \n",
    "    # Iterate through each tweet in the given list of tweets\n",
    "    for tweet in tweets:\n",
    "        # Tokenize and preprocess the tweet using the preprocess_tweet function\n",
    "        tokens = preprocess_tweet(tweet)\n",
    "        \n",
    "        # Iterate through each token in the preprocessed tokens\n",
    "        for token in tokens:\n",
    "            # Increment the count for the current token in the word_count dictionary\n",
    "            word_count[token] += 1\n",
    "    \n",
    "    # Return the word_count dictionary containing word frequencies\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41d2c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word counts for tweets with positive sentiment\n",
    "word_count_positive = calculate_word_counts(df_train[df_train['sentiment'] == 'positive']['text'])\n",
    "\n",
    "# Calculate word counts for tweets with negative sentiment\n",
    "word_count_negative = calculate_word_counts(df_train[df_train['sentiment'] == 'negative']['text'])\n",
    "\n",
    "# Calculate word counts for tweets with neutral sentiment\n",
    "word_count_neutral = calculate_word_counts(df_train[df_train['sentiment'] == 'neutral']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8195818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(word_count, total_words, laplacian_smoothing=1):\n",
    "    # Create an empty dictionary to store the likelihood values\n",
    "    likelihood = {}\n",
    "    \n",
    "    # Get the number of unique words in the vocabulary\n",
    "    vocabulary_size = len(word_count)\n",
    "\n",
    "    # Iterate through each word and its corresponding count in the word_count dictionary\n",
    "    for word, count in word_count.items():\n",
    "        # Calculate the likelihood using Laplacian smoothing formula\n",
    "        # Laplacian smoothing is used to handle unseen words in training data\n",
    "        # The formula is (count + smoothing) / (total_words + smoothing * vocabulary_size)\n",
    "        likelihood[word] = (count + laplacian_smoothing) / (total_words + laplacian_smoothing * vocabulary_size)\n",
    "\n",
    "    # Return the calculated likelihood dictionary\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8be2c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_positive = calculate_likelihood(word_count_positive, df.shape[0]-1, laplacian_smoothing=1)\n",
    "likelihood_negative = calculate_likelihood(word_count_negative, df.shape[0]-1, laplacian_smoothing=1)\n",
    "likelihood_neutral = calculate_likelihood(word_count_neutral, df.shape[0]-1, laplacian_smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21939d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_positive\n",
    "sorted_dict_positive = dict(sorted(likelihood_positive.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f519e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_negative\n",
    "sorted_dict_negative = dict(sorted(likelihood_negative.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29085b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_neutral\n",
    "sorted_dict_neutral = dict(sorted(likelihood_neutral.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a02b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_prior(sentiment, data):\n",
    "    # Calculate the natural logarithm of the ratio of tweets with the specified sentiment to the total number of tweets\n",
    "    log_prior = math.log(len(data[data['sentiment'] == sentiment]) / len(data))\n",
    "    \n",
    "    # Return the calculated log prior\n",
    "    return log_prior\n",
    "\n",
    "# Calculate the log prior for tweets with positive sentiment\n",
    "log_prior_positive = calculate_log_prior('positive', df)\n",
    "\n",
    "# Calculate the log prior for tweets with negative sentiment\n",
    "log_prior_negative = calculate_log_prior('negative', df)\n",
    "\n",
    "# Calculate the log prior for tweets with neutral sentiment\n",
    "log_prior_neutral = calculate_log_prior('neutral', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db9eefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of log-likelihood values for positive sentiment\n",
    "log_likelihood_positive = {word: math.log(prob) for word, prob in likelihood_positive.items()}\n",
    "\n",
    "# Create a dictionary of log-likelihood values for negative sentiment\n",
    "log_likelihood_negative = {word: math.log(prob) for word, prob in likelihood_negative.items()}\n",
    "\n",
    "# Create a dictionary of log-likelihood values for neutral sentiment\n",
    "log_likelihood_neutral = {word: math.log(prob) for word, prob in likelihood_neutral.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "780724cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tweet_with_scores(tweet, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                               log_prior_positive, log_prior_negative, log_prior_neutral):\n",
    "    # Tokenize and preprocess the input tweet\n",
    "    tokens = preprocess_tweet(tweet)\n",
    "\n",
    "    # Calculate the log scores for each sentiment category\n",
    "    log_score_positive = log_prior_positive + sum([log_likelihood_positive.get(token, 0) for token in tokens])\n",
    "    log_score_negative = log_prior_negative + sum([log_likelihood_negative.get(token, 0) for token in tokens])\n",
    "    log_score_neutral = log_prior_neutral + sum([log_likelihood_neutral.get(token, 0) for token in tokens])\n",
    "\n",
    "    # Store the sentiment scores in a dictionary\n",
    "    sentiment_scores = {\n",
    "        'positive': log_score_positive,\n",
    "        'negative': log_score_negative,\n",
    "        'neutral': log_score_neutral\n",
    "    }\n",
    "\n",
    "    # Determine the predicted sentiment based on the highest sentiment score\n",
    "    predicted_sentiment = max(sentiment_scores, key=sentiment_scores.get)\n",
    "    \n",
    "    # Return the predicted sentiment and the sentiment scores\n",
    "    return predicted_sentiment #, sentiment_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f23514",
   "metadata": {},
   "source": [
    "# Classification on Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4b25a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_test = []\n",
    "for tweet in df_test['text']:\n",
    "    result = classify_tweet_with_scores(tweet,log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                               log_prior_positive, log_prior_negative, log_prior_neutral)\n",
    "    loc_test.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be7f722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ground Truth\n",
    "test_gt = df_test['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79c9eb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.5212224108658744\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "correct_count = sum(1 for predicted, actual in zip(loc_test, test_gt) if predicted == actual)\n",
    "accuracy = correct_count / len(loc_test)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e83e6",
   "metadata": {},
   "source": [
    "# Classification on Train DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e4a0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_train = []\n",
    "for tweet in df_train['text']:\n",
    "    result = classify_tweet_with_scores(tweet,log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                               log_prior_positive, log_prior_negative, log_prior_neutral)\n",
    "    loc_train.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37e76ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = df_train['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11c5c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.3347161572052402\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "correct_count = sum(1 for predicted, actual in zip(loc_train, train_gt) if predicted == actual)\n",
    "accuracy = correct_count / len(loc_train)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420afe0d",
   "metadata": {},
   "source": [
    "# Pre-built Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7f689acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):        \n",
    "    # converting to lowercase, removing URL links, special characters, punctuations...\n",
    "    text = text.lower() # converting to lowercase\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # removing URL links\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text) # removing number \n",
    "    text = re.sub('<.*?>+', '', text) # removing special characters, \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[’“”…]', '', text)\n",
    "   \n",
    "    #removing emoji: \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)   \n",
    "\n",
    "   # removing short form: \n",
    "    \n",
    "    text=re.sub(\"isn't\",'is not',text)\n",
    "    text=re.sub(\"he's\",'he is',text)\n",
    "    text=re.sub(\"wasn't\",'was not',text)\n",
    "    text=re.sub(\"there's\",'there is',text)\n",
    "    text=re.sub(\"couldn't\",'could not',text)\n",
    "    text=re.sub(\"won't\",'will not',text)\n",
    "    text=re.sub(\"they're\",'they are',text)\n",
    "    text=re.sub(\"she's\",'she is',text)\n",
    "    text=re.sub(\"There's\",'there is',text)\n",
    "    text=re.sub(\"wouldn't\",'would not',text)\n",
    "    text=re.sub(\"haven't\",'have not',text)\n",
    "    text=re.sub(\"That's\",'That is',text)\n",
    "    text=re.sub(\"you've\",'you have',text)\n",
    "    text=re.sub(\"He's\",'He is',text)\n",
    "    text=re.sub(\"what's\",'what is',text)\n",
    "    text=re.sub(\"weren't\",'were not',text)\n",
    "    text=re.sub(\"we're\",'we are',text)\n",
    "    text=re.sub(\"hasn't\",'has not',text)\n",
    "    text=re.sub(\"you'd\",'you would',text)\n",
    "    text=re.sub(\"shouldn't\",'should not',text)\n",
    "    text=re.sub(\"let's\",'let us',text)\n",
    "    text=re.sub(\"they've\",'they have',text)\n",
    "    text=re.sub(\"You'll\",'You will',text)\n",
    "    text=re.sub(\"i'm\",'i am',text)\n",
    "    text=re.sub(\"we've\",'we have',text)\n",
    "    text=re.sub(\"it's\",'it is',text)\n",
    "    text=re.sub(\"don't\",'do not',text)\n",
    "    text=re.sub(\"that´s\",'that is',text)\n",
    "    text=re.sub(\"I´m\",'I am',text)\n",
    "    text=re.sub(\"it’s\",'it is',text)\n",
    "    text=re.sub(\"she´s\",'she is',text)\n",
    "    text=re.sub(\"he’s'\",'he is',text)\n",
    "    text=re.sub('I’m','I am',text)\n",
    "    text=re.sub('I’d','I did',text)\n",
    "    text=re.sub(\"he’s'\",'he is',text)\n",
    "    text=re.sub('there’s','there is',text)\n",
    "    \n",
    "     \n",
    "    return text\n",
    "    \n",
    "dt_train_cleaned = df_train['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "078f6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_cleaned = pd.DataFrame(dt_train_cleaned)  \n",
    "dt_train_cleaned['sentiment']=df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d74c1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words()\n",
    "dt_train_cleaned['no_sw'] = dt_train_cleaned['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "049cc199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             id responded\n",
       "1                                  sooo sad miss san diego\n",
       "2                                            boss bullying\n",
       "3                                          interview leave\n",
       "4                                      put releases bought\n",
       "                               ...                        \n",
       "27476                  wish denver husband lost job afford\n",
       "27477    ive wondered rake client made clear net force ...\n",
       "27478         yay enjoy break probably hectic weekend xxxx\n",
       "27479                                                worth\n",
       "27480                         flirting atg smiles yay hugs\n",
       "Name: no_sw, Length: 27480, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train_cleaned['no_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8570104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_cleaned.sentiment = [0 if each == \"negative\" else 1 if each == \"positive\" else 2 for each in df_train.sentiment]\n",
    "tokenized_review=dt_train_cleaned['no_sw'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "532b7ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>no_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>2</td>\n",
       "      <td>id responded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>0</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>0</td>\n",
       "      <td>boss bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>0</td>\n",
       "      <td>interview leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>put releases bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>0</td>\n",
       "      <td>wish denver husband lost job afford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>ive wondered rake client made clear net force ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>1</td>\n",
       "      <td>yay enjoy break probably hectic weekend xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>1</td>\n",
       "      <td>worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>2</td>\n",
       "      <td>flirting atg smiles yay hugs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "0                      id have responded if i were going          2   \n",
       "1             sooo sad i will miss you here in san diego          0   \n",
       "2                                 my boss is bullying me          0   \n",
       "3                          what interview leave me alone          0   \n",
       "4       sons of  why couldnt they put them on the rel...          0   \n",
       "...                                                  ...        ...   \n",
       "27476   wish we could come see u on denver  husband l...          0   \n",
       "27477   ive wondered about rake to  the client has ma...          0   \n",
       "27478   yay good for both of you enjoy the break  you...          1   \n",
       "27479                              but it was worth it            1   \n",
       "27480     all this flirting going on  the atg smiles ...          2   \n",
       "\n",
       "                                                   no_sw  \n",
       "0                                           id responded  \n",
       "1                                sooo sad miss san diego  \n",
       "2                                          boss bullying  \n",
       "3                                        interview leave  \n",
       "4                                    put releases bought  \n",
       "...                                                  ...  \n",
       "27476                wish denver husband lost job afford  \n",
       "27477  ive wondered rake client made clear net force ...  \n",
       "27478       yay enjoy break probably hectic weekend xxxx  \n",
       "27479                                              worth  \n",
       "27480                       flirting atg smiles yay hugs  \n",
       "\n",
       "[27480 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d05a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [id, responded]\n",
       "1                            [sooo, sad, miss, san, diego]\n",
       "2                                         [boss, bullying]\n",
       "3                                       [interview, leave]\n",
       "4                                  [put, releases, bought]\n",
       "                               ...                        \n",
       "27476           [wish, denver, husband, lost, job, afford]\n",
       "27477    [ive, wondered, rake, client, made, clear, net...\n",
       "27478    [yay, enjoy, break, probably, hectic, weekend,...\n",
       "27479                                              [worth]\n",
       "27480                   [flirting, atg, smiles, yay, hugs]\n",
       "Name: no_sw, Length: 27480, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c3404941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friday/opt/anaconda3/envs/vertualEnvPython/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dt_train_cleaned['no_sw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a46bbe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=text_counts\n",
    "y=dt_train_cleaned['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "682b07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB model accuracy is 59.35%\n",
      "------------------------------------------------\n",
      "Confusion Matrix:\n",
      "      0     1    2\n",
      "0  1107   167  319\n",
      "1   207  1231  259\n",
      "2   702   580  924\n",
      "------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.69      0.61      1593\n",
      "           1       0.62      0.73      0.67      1697\n",
      "           2       0.62      0.42      0.50      2206\n",
      "\n",
      "    accuracy                           0.59      5496\n",
      "   macro avg       0.60      0.61      0.59      5496\n",
      "weighted avg       0.60      0.59      0.58      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "CNB = ComplementNB()\n",
    "CNB.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "predicted = CNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
    "\n",
    "print('ComplementNB model accuracy is',str('{:04.2f}'.format(accuracy_score*100))+'%')\n",
    "print('------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))\n",
    "print('------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d6c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
